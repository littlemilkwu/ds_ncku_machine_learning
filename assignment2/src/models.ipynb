{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "RANDOM_STATE = 11\n",
    "pd.set_option('display.max_columns', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv(\"../output/train_X.csv\")\n",
    "train_y = pd.read_csv(\"../output/train_y.csv\").squeeze()\n",
    "\n",
    "test_X = pd.read_csv(\"../output/test_X.csv\")\n",
    "test_y = pd.read_csv(\"../output/test_y.csv\").squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape   : (37499, 55)\n",
      "train_y shape   : (37499,)\n",
      "--------------------\n",
      "val_X shape     : (9375, 55)\n",
      "val_y shape     : (9375,)\n",
      "--------------------\n",
      "test_X shape    : (11718, 55)\n",
      "test_y shape    : (11718,)\n"
     ]
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, train_size=0.8, random_state=RANDOM_STATE)\n",
    "print('{:<15} :'.format('train_X shape'), train_X.shape)\n",
    "print('{:<15} :'.format('train_y shape'), train_y.shape)\n",
    "print('-'*20)\n",
    "print('{:<15} :'.format('val_X shape'), val_X.shape)\n",
    "print('{:<15} :'.format('val_y shape'), val_y.shape)\n",
    "print('-'*20)\n",
    "print('{:<15} :'.format('test_X shape'), test_X.shape)\n",
    "print('{:<15} :'.format('test_y shape'), test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_cols = [\"airbags\", \"is_esc\", \"is_adjustable_steering\", \"is_tpms\",\n",
    "#             \"is_parking_sensors\", \"is_parking_camera\", \"is_front_fog_lights\",\n",
    "#             \"is_rear_window_wiper\", \"is_rear_window_washer\", \"is_rear_window_defogger\", \"is_brake_assist\", \"\"]\n",
    "# num_cols = [\"policy_tenure\", \"age_of_car\", \"age_of_policyholder\", \"area_cluster\",\n",
    "#             \"population_density\", \"model\", \"max_torque\", \"max_power\",\n",
    "#             \"engine_type\", \"displacement\", \"gear_box\", \"displacement\",\n",
    "#             \"turning_radius\", \"length\", \"width\", \"height\",\n",
    "#             \"gross_weight\", ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "<pre>\n",
    "若是類別資料，計算兩種狀況各自的條件機率\n",
    "若是數值資料，透過 guassian MLE 來計算可能性\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'divide_cat_num_cols' from 'toolbox' (/Users/littlemilk/Documents/成大數據所/碩一/機器學習/assignment/assignment2/src/toolbox.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtoolbox\u001b[39;00m \u001b[39mimport\u001b[39;00m divide_cat_num_cols\n\u001b[1;32m      2\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mNaiveBayesClassifier\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'divide_cat_num_cols' from 'toolbox' (/Users/littlemilk/Documents/成大數據所/碩一/機器學習/assignment/assignment2/src/toolbox.py)"
     ]
    }
   ],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _divide_cat_num_cols(self):\n",
    "        num_cols = []\n",
    "        cat_cols = []\n",
    "        for col in self.X.columns:\n",
    "            if len(self.X[col].unique()) > 5:\n",
    "                num_cols.append(col)\n",
    "            else:\n",
    "                cat_cols.append(col)\n",
    "        return num_cols, cat_cols\n",
    "\n",
    "    def _likelihood(self, x, mean, var):\n",
    "        eps = 1e-4\n",
    "        # print((1 / np.sqrt(2 * np.pi * var + eps)) * np.exp( -1 * (x-mean)**2 / (2 * var + eps)))\n",
    "        return (1 / np.sqrt(2 * np.pi * var + eps)) * np.exp( -1 * (x-mean)**2 / (2 * var + eps))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.num_cols, self.cat_cols = self._divide_cat_num_cols()\n",
    "        self.y_classes = y.unique()\n",
    "        self.parameter = dict()\n",
    "\n",
    "        for c in self.y_classes:\n",
    "            mask = (y == c)\n",
    "            c_X = X[mask]\n",
    "            self.parameter[c] = dict()\n",
    "            for col in self.X.columns:\n",
    "                if col in self.num_cols:\n",
    "                    # 數值特徵紀錄 mean, var\n",
    "                    self.parameter[c][col] = [\n",
    "                        round(c_X[col].mean(), 2),\n",
    "                        round(c_X[col].var(), 2)\n",
    "                    ]\n",
    "                elif col in self.cat_cols:\n",
    "                    # 類別特徵直接計算各類別的機率\n",
    "                    self.parameter[c][col] = dict()\n",
    "                    for cat in c_X[col].unique():\n",
    "                        mask = (c_X[col] == cat)\n",
    "                        self.parameter[c][col][cat] = round(len(c_X.loc[mask] ) / len(c_X), 2)\n",
    "        return self.parameter\n",
    "    def _calc_prob(self, X):\n",
    "        all_prob = []\n",
    "        for c in self.y_classes:\n",
    "            c_prob = 1\n",
    "            for key, value in X.items():\n",
    "                if key in self.num_cols:\n",
    "                    mean, var = self.parameter[c][key]\n",
    "                    c_prob *= self._likelihood(value, mean, var)\n",
    "                elif key in self.cat_cols:\n",
    "                    c_prob *= self.parameter[c][key][value]\n",
    "            all_prob.append(c_prob)\n",
    "        return all_prob\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        pred_y = np.array([self._calc_prob(X) for i, X in test_X.iterrows()])\n",
    "        return pred_y.argmax(axis=1)\n",
    "\n",
    "    def evaluate(self):\n",
    "        pass\n",
    "    \n",
    "\n",
    "nb_clf = NaiveBayesClassifier()\n",
    "nb_clf.fit(train_X, train_y)\n",
    "pred_y = nb_clf.predict(test_X)\n",
    "evaluate(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary ~: 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [73], line 103\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    102\u001b[0m dt_clf \u001b[39m=\u001b[39m DecisionTreeClassifier()\n\u001b[0;32m--> 103\u001b[0m dt_clf\u001b[39m.\u001b[39;49mfit(train_X, train_y)\n",
      "Cell \u001b[0;32mIn [73], line 97\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m     96\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot \u001b[39m=\u001b[39m Node(X, y, \u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m---> 97\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdivide_branch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n",
      "Cell \u001b[0;32mIn [73], line 85\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.divide_branch\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     81\u001b[0m     node\u001b[39m.\u001b[39ml_child \u001b[39m=\u001b[39m Node(\n\u001b[1;32m     82\u001b[0m         node\u001b[39m.\u001b[39mX[best_mask], node\u001b[39m.\u001b[39my[best_mask],\n\u001b[1;32m     83\u001b[0m         feat_candidate\u001b[39m=\u001b[39m[feat \u001b[39mfor\u001b[39;00m feat \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39mfeat_candidate \u001b[39mif\u001b[39;00m feat \u001b[39m!=\u001b[39m best_feat])\n\u001b[1;32m     84\u001b[0m     \u001b[39m# print('yes')\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdivide_branch(node\u001b[39m.\u001b[39;49ml_child)\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(node\u001b[39m.\u001b[39my[\u001b[39m~\u001b[39mbest_mask]) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     89\u001b[0m     \u001b[39m# 右邊分支先確認數量\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     node\u001b[39m.\u001b[39mr_child \u001b[39m=\u001b[39m Node(\n\u001b[1;32m     91\u001b[0m         node\u001b[39m.\u001b[39mX[\u001b[39m~\u001b[39mbest_mask], node\u001b[39m.\u001b[39my[\u001b[39m~\u001b[39mbest_mask],\n\u001b[1;32m     92\u001b[0m         feat_candidate\u001b[39m=\u001b[39m[feat \u001b[39mfor\u001b[39;00m feat \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39mfeat_candidate \u001b[39mif\u001b[39;00m feat \u001b[39m!=\u001b[39m best_feat])\n",
      "Cell \u001b[0;32mIn [73], line 85\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.divide_branch\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     81\u001b[0m     node\u001b[39m.\u001b[39ml_child \u001b[39m=\u001b[39m Node(\n\u001b[1;32m     82\u001b[0m         node\u001b[39m.\u001b[39mX[best_mask], node\u001b[39m.\u001b[39my[best_mask],\n\u001b[1;32m     83\u001b[0m         feat_candidate\u001b[39m=\u001b[39m[feat \u001b[39mfor\u001b[39;00m feat \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39mfeat_candidate \u001b[39mif\u001b[39;00m feat \u001b[39m!=\u001b[39m best_feat])\n\u001b[1;32m     84\u001b[0m     \u001b[39m# print('yes')\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdivide_branch(node\u001b[39m.\u001b[39;49ml_child)\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(node\u001b[39m.\u001b[39my[\u001b[39m~\u001b[39mbest_mask]) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     89\u001b[0m     \u001b[39m# 右邊分支先確認數量\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     node\u001b[39m.\u001b[39mr_child \u001b[39m=\u001b[39m Node(\n\u001b[1;32m     91\u001b[0m         node\u001b[39m.\u001b[39mX[\u001b[39m~\u001b[39mbest_mask], node\u001b[39m.\u001b[39my[\u001b[39m~\u001b[39mbest_mask],\n\u001b[1;32m     92\u001b[0m         feat_candidate\u001b[39m=\u001b[39m[feat \u001b[39mfor\u001b[39;00m feat \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39mfeat_candidate \u001b[39mif\u001b[39;00m feat \u001b[39m!=\u001b[39m best_feat])\n",
      "    \u001b[0;31m[... skipping similar frames: DecisionTreeClassifier.divide_branch at line 85 (4 times)]\u001b[0m\n",
      "Cell \u001b[0;32mIn [73], line 85\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.divide_branch\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     81\u001b[0m     node\u001b[39m.\u001b[39ml_child \u001b[39m=\u001b[39m Node(\n\u001b[1;32m     82\u001b[0m         node\u001b[39m.\u001b[39mX[best_mask], node\u001b[39m.\u001b[39my[best_mask],\n\u001b[1;32m     83\u001b[0m         feat_candidate\u001b[39m=\u001b[39m[feat \u001b[39mfor\u001b[39;00m feat \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39mfeat_candidate \u001b[39mif\u001b[39;00m feat \u001b[39m!=\u001b[39m best_feat])\n\u001b[1;32m     84\u001b[0m     \u001b[39m# print('yes')\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdivide_branch(node\u001b[39m.\u001b[39;49ml_child)\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(node\u001b[39m.\u001b[39my[\u001b[39m~\u001b[39mbest_mask]) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     89\u001b[0m     \u001b[39m# 右邊分支先確認數量\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     node\u001b[39m.\u001b[39mr_child \u001b[39m=\u001b[39m Node(\n\u001b[1;32m     91\u001b[0m         node\u001b[39m.\u001b[39mX[\u001b[39m~\u001b[39mbest_mask], node\u001b[39m.\u001b[39my[\u001b[39m~\u001b[39mbest_mask],\n\u001b[1;32m     92\u001b[0m         feat_candidate\u001b[39m=\u001b[39m[feat \u001b[39mfor\u001b[39;00m feat \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39mfeat_candidate \u001b[39mif\u001b[39;00m feat \u001b[39m!=\u001b[39m best_feat])\n",
      "Cell \u001b[0;32mIn [73], line 88\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.divide_branch\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[39m# print('yes')\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdivide_branch(node\u001b[39m.\u001b[39ml_child)\n\u001b[0;32m---> 88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(node\u001b[39m.\u001b[39my[\u001b[39m~\u001b[39;49mbest_mask]) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     89\u001b[0m     \u001b[39m# 右邊分支先確認數量\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     node\u001b[39m.\u001b[39mr_child \u001b[39m=\u001b[39m Node(\n\u001b[1;32m     91\u001b[0m         node\u001b[39m.\u001b[39mX[\u001b[39m~\u001b[39mbest_mask], node\u001b[39m.\u001b[39my[\u001b[39m~\u001b[39mbest_mask],\n\u001b[1;32m     92\u001b[0m         feat_candidate\u001b[39m=\u001b[39m[feat \u001b[39mfor\u001b[39;00m feat \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39mfeat_candidate \u001b[39mif\u001b[39;00m feat \u001b[39m!=\u001b[39m best_feat])\n\u001b[1;32m     93\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdivide_branch(node\u001b[39m.\u001b[39mr_child)\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary ~: 'NoneType'"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    '''\n",
    "        特徵：data, 剩餘 features, left_child, right_child\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def _calc_gini(y):\n",
    "        total_len = len(y)\n",
    "        if total_len == 0:\n",
    "            return 0\n",
    "        pos_len = len(y[y==1])\n",
    "        neg_len = total_len - pos_len\n",
    "        return 1 - (pos_len / total_len)**2 - (neg_len / total_len)**2\n",
    "\n",
    "    def __init__(self, X, y, feat_candidate):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.feat_candidate = feat_candidate\n",
    "        self.gini = self._calc_gini(y)\n",
    "        self.l_child = None\n",
    "        self.r_child = None\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    '''\n",
    "        * 二元類別：\n",
    "        * 多元類別：\n",
    "        * 數值特徵：sort -> 中位數切分\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def _calc_gini(y):\n",
    "        total_len = len(y)\n",
    "        pos_len = len(y[y==1])\n",
    "        neg_len = total_len - pos_len\n",
    "        return 1 - (pos_len / total_len)**2 - (neg_len / total_len)**2\n",
    "\n",
    "    def __init__(self):\n",
    "        self.min_num = 15\n",
    "        pass\n",
    "\n",
    "    def choose_best_feat(self, node):\n",
    "        best_feat = node.feat_candidate[0]\n",
    "        best_gini_gain = 0\n",
    "        best_mask = None\n",
    "        feat_del = []\n",
    "        for feat in node.feat_candidate:\n",
    "            uniq = node.X[feat].unique()\n",
    "            if len(uniq) == 1:\n",
    "                # 類別，單獨值，此類別無用處\n",
    "                feat_del.append(feat)\n",
    "                continue\n",
    "            elif len(uniq) == 2:\n",
    "                # 類別\n",
    "                mask = (node.X[feat] == uniq[0])\n",
    "            else:\n",
    "                # 數值\n",
    "                median = np.median(node.X[feat].to_numpy())\n",
    "                mask = (node.X[feat] <= median)\n",
    "\n",
    "            # print('---choose feature')\n",
    "            gini_gain = (node.gini\n",
    "                - len(node.X[mask]) / len(node.X) * self._calc_gini(node.y[mask])\n",
    "                - len(node.X[~mask]) / len(node.X) * self._calc_gini(node.y[~mask]))\n",
    "            if gini_gain > best_gini_gain:\n",
    "                best_gini_gain = gini_gain\n",
    "                best_feat = feat\n",
    "                best_mask = mask\n",
    "        return best_feat, best_mask, feat_del\n",
    "\n",
    "    def divide_branch(self, node):\n",
    "        if node.gini == 0 or len(node.feat_candidate) == 0 or len(node.X) < self.min_num:\n",
    "            # 乾淨 node / 沒特徵可用 / 小於最小數量\n",
    "            return None\n",
    "        \n",
    "        best_feat, best_mask, feat_del = self.choose_best_feat(node)\n",
    "        node.feat_candidate = [feat for feat in node.feat_candidate if feat not in feat_del]\n",
    "\n",
    "        # print('--new branch')\n",
    "        \n",
    "        \n",
    "        if best_mask is not None:\n",
    "            # 左邊分支確認有找到\n",
    "            node.l_child = Node(\n",
    "                node.X[best_mask], node.y[best_mask],\n",
    "                feat_candidate=[feat for feat in node.feat_candidate if feat != best_feat])\n",
    "            # print('yes')\n",
    "            self.divide_branch(node.l_child)\n",
    "            \n",
    "\n",
    "        if len(node.y[~best_mask]) != 0:\n",
    "            # 右邊分支先確認數量\n",
    "            node.r_child = Node(\n",
    "                node.X[~best_mask], node.y[~best_mask],\n",
    "                feat_candidate=[feat for feat in node.feat_candidate if feat != best_feat])\n",
    "            self.divide_branch(node.r_child)\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        self.root = Node(X, y, list(X.columns))\n",
    "        self.divide_branch(self.root)\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self):\n",
    "        pass\n",
    "\n",
    "    def evaluate(self):\n",
    "        pass\n",
    "    def predict(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier: sklearn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy        : 0.5640040962621607\n",
      "Precision       : 0.09199477514461653\n",
      "Recall          : 0.6698369565217391\n",
      "F1              : 0.16177194421657096\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.56      0.71     10982\n",
      "           1       0.09      0.67      0.16       736\n",
      "\n",
      "    accuracy                           0.56     11718\n",
      "   macro avg       0.53      0.61      0.43     11718\n",
      "weighted avg       0.91      0.56      0.67     11718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=5,\n",
    "    class_weight='balanced' ,random_state=RANDOM_STATE)\n",
    "\n",
    "# rf_clf = RandomForestClassifier(\n",
    "#     n_estimators=100, max_depth=2, \n",
    "#     class_weight={0:1, 1:17} ,random_state=RANDOM_STATE)\n",
    "rf_clf.fit(train_X, train_y)\n",
    "pred_y = rf_clf.predict(test_X[train_X.columns])\n",
    "evaluate(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost, Catboost, LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "lgb_clf = LGBMClassifier(class_weight=\"balanced\")\n",
    "xgb_clf = XGBClassifier(scale_pos_weight=99)\n",
    "cat_clf = CatBoostClassifier(auto_class_weights='Balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy        : 0.6183649086874893\n",
      "Precision       : 0.09267335368512865\n",
      "Recall          : 0.5774456521739131\n",
      "F1              : 0.15971439308530627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.62      0.75     10982\n",
      "           1       0.09      0.58      0.16       736\n",
      "\n",
      "    accuracy                           0.62     11718\n",
      "   macro avg       0.52      0.60      0.46     11718\n",
      "weighted avg       0.90      0.62      0.72     11718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgb_clf.fit(train_X, train_y)\n",
    "pred_y = lgb_clf.predict(test_X)\n",
    "evaluate(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy        : 0.3872674517835808\n",
      "Precision       : 0.07549407114624505\n",
      "Recall          : 0.7785326086956522\n",
      "F1              : 0.13764112418928656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.36      0.52     10982\n",
      "           1       0.08      0.78      0.14       736\n",
      "\n",
      "    accuracy                           0.39     11718\n",
      "   macro avg       0.52      0.57      0.33     11718\n",
      "weighted avg       0.90      0.39      0.50     11718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf.fit(train_X, train_y)\n",
    "pred_y = xgb_clf.predict(test_X[train_X.columns])\n",
    "evaluate(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy        : 0.6804062126642771\n",
      "Precision       : 0.09480204686237544\n",
      "Recall          : 0.4782608695652174\n",
      "F1              : 0.15823780624859518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.69      0.80     10982\n",
      "           1       0.09      0.48      0.16       736\n",
      "\n",
      "    accuracy                           0.68     11718\n",
      "   macro avg       0.52      0.59      0.48     11718\n",
      "weighted avg       0.90      0.68      0.76     11718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat_clf.fit(train_X, train_y, verbose=0)\n",
    "pred_y = cat_clf.predict(test_X)\n",
    "evaluate(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation\n",
    "<pre>\n",
    "k = 3, 5, 10\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_validation(train_X.to_numpy(), train_y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(30000, 55) (7499, 55)\n",
      "(30000,) (7499,)\n",
      "1\n",
      "(30000, 55) (7499, 55)\n",
      "(30000,) (7499,)\n",
      "2\n",
      "(30000, 55) (7499, 55)\n",
      "(30000,) (7499,)\n",
      "3\n",
      "(30000, 55) (7499, 55)\n",
      "(30000,) (7499,)\n",
      "4\n",
      "(30000, 55) (7499, 55)\n",
      "(30000,) (7499,)\n"
     ]
    }
   ],
   "source": [
    "for train_X, val_X, train_y, val_y, i in cv:\n",
    "    print(i)\n",
    "    print(train_X.shape, val_X.shape)\n",
    "    print(train_y.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d43e22b5d3a7a0bd2e205ac27062b2ba3e10bf7033fb4f991038673b60a6900c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
