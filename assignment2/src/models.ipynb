{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "RANDOM_STATE = 11\n",
    "pd.set_option('display.max_columns', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv(\"../output/train_X.csv\")\n",
    "train_y = pd.read_csv(\"../output/train_y.csv\").squeeze()\n",
    "\n",
    "test_X = pd.read_csv(\"../output/test_X.csv\")\n",
    "test_y = pd.read_csv(\"../output/test_y.csv\").squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape   : (37499, 55)\n",
      "train_y shape   : (37499,)\n",
      "--------------------\n",
      "val_X shape     : (9375, 55)\n",
      "val_y shape     : (9375,)\n",
      "--------------------\n",
      "test_X shape    : (11718, 55)\n",
      "test_y shape    : (11718,)\n"
     ]
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, train_size=0.8, random_state=RANDOM_STATE)\n",
    "print('{:<15} :'.format('train_X shape'), train_X.shape)\n",
    "print('{:<15} :'.format('train_y shape'), train_y.shape)\n",
    "print('-'*20)\n",
    "print('{:<15} :'.format('val_X shape'), val_X.shape)\n",
    "print('{:<15} :'.format('val_y shape'), val_y.shape)\n",
    "print('-'*20)\n",
    "print('{:<15} :'.format('test_X shape'), test_X.shape)\n",
    "print('{:<15} :'.format('test_y shape'), test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_cols = [\"airbags\", \"is_esc\", \"is_adjustable_steering\", \"is_tpms\",\n",
    "#             \"is_parking_sensors\", \"is_parking_camera\", \"is_front_fog_lights\",\n",
    "#             \"is_rear_window_wiper\", \"is_rear_window_washer\", \"is_rear_window_defogger\", \"is_brake_assist\", \"\"]\n",
    "# num_cols = [\"policy_tenure\", \"age_of_car\", \"age_of_policyholder\", \"area_cluster\",\n",
    "#             \"population_density\", \"model\", \"max_torque\", \"max_power\",\n",
    "#             \"engine_type\", \"displacement\", \"gear_box\", \"displacement\",\n",
    "#             \"turning_radius\", \"length\", \"width\", \"height\",\n",
    "#             \"gross_weight\", ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "<pre>\n",
    "若是類別資料，計算兩種狀況各自的條件機率\n",
    "若是數值資料，透過 guassian MLE 來計算可能性\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy        : 0.46944871138419525\n",
      "Precision       : 0.06671936758893281\n",
      "Recall          : 0.5733695652173914\n",
      "F1              : 0.11952981164141055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.46      0.62     10982\n",
      "           1       0.07      0.57      0.12       736\n",
      "\n",
      "    accuracy                           0.47     11718\n",
      "   macro avg       0.50      0.52      0.37     11718\n",
      "weighted avg       0.89      0.47      0.59     11718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _divide_cat_num_cols(self):\n",
    "        num_cols = []\n",
    "        cat_cols = []\n",
    "        for col in self.X.columns:\n",
    "            if len(self.X[col].unique()) > 5:\n",
    "                num_cols.append(col)\n",
    "            else:\n",
    "                cat_cols.append(col)\n",
    "        return num_cols, cat_cols\n",
    "\n",
    "    def _likelihood(self, x, mean, var):\n",
    "        eps = 1e-4\n",
    "        # print((1 / np.sqrt(2 * np.pi * var + eps)) * np.exp( -1 * (x-mean)**2 / (2 * var + eps)))\n",
    "        return (1 / np.sqrt(2 * np.pi * var + eps)) * np.exp( -1 * (x-mean)**2 / (2 * var + eps))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.num_cols, self.cat_cols = self._divide_cat_num_cols()\n",
    "        self.y_classes = y.unique()\n",
    "        self.parameter = dict()\n",
    "\n",
    "        for c in self.y_classes:\n",
    "            mask = (y == c)\n",
    "            c_X = X[mask]\n",
    "            self.parameter[c] = dict()\n",
    "            for col in self.X.columns:\n",
    "                if col in self.num_cols:\n",
    "                    # 數值特徵紀錄 mean, var\n",
    "                    self.parameter[c][col] = [\n",
    "                        round(c_X[col].mean(), 2),\n",
    "                        round(c_X[col].var(), 2)\n",
    "                    ]\n",
    "                elif col in self.cat_cols:\n",
    "                    # 類別特徵直接計算各類別的機率\n",
    "                    self.parameter[c][col] = dict()\n",
    "                    for cat in c_X[col].unique():\n",
    "                        mask = (c_X[col] == cat)\n",
    "                        self.parameter[c][col][cat] = round(len(c_X.loc[mask] ) / len(c_X), 2)\n",
    "        return self.parameter\n",
    "    def _calc_prob(self, X):\n",
    "        all_prob = []\n",
    "        for c in self.y_classes:\n",
    "            c_prob = 1\n",
    "            for key, value in X.items():\n",
    "                if key in self.num_cols:\n",
    "                    mean, var = self.parameter[c][key]\n",
    "                    c_prob *= self._likelihood(value, mean, var)\n",
    "                elif key in self.cat_cols:\n",
    "                    c_prob *= self.parameter[c][key][value]\n",
    "            all_prob.append(c_prob)\n",
    "        return all_prob\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        pred_y = np.array([self._calc_prob(X) for i, X in test_X.iterrows()])\n",
    "        return pred_y.argmax(axis=1)\n",
    "\n",
    "    def evaluate(self):\n",
    "        pass\n",
    "    \n",
    "\n",
    "nb_clf = NaiveBayesClassifier()\n",
    "nb_clf.fit(train_X, train_y)\n",
    "pred_y = nb_clf.predict(test_X)\n",
    "evaluate(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self):\n",
    "        pass\n",
    "\n",
    "    def evaluate(self):\n",
    "        pass\n",
    "    def predict(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier: sklearn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy        : 0.5640040962621607\n",
      "Precision       : 0.09199477514461653\n",
      "Recall          : 0.6698369565217391\n",
      "F1              : 0.16177194421657096\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.56      0.71     10982\n",
      "           1       0.09      0.67      0.16       736\n",
      "\n",
      "    accuracy                           0.56     11718\n",
      "   macro avg       0.53      0.61      0.43     11718\n",
      "weighted avg       0.91      0.56      0.67     11718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=5,\n",
    "    class_weight='balanced' ,random_state=RANDOM_STATE)\n",
    "\n",
    "# rf_clf = RandomForestClassifier(\n",
    "#     n_estimators=100, max_depth=2, \n",
    "#     class_weight={0:1, 1:17} ,random_state=RANDOM_STATE)\n",
    "rf_clf.fit(train_X, train_y)\n",
    "pred_y = rf_clf.predict(test_X[train_X.columns])\n",
    "evaluate(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost, Catboost, LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "lgb_clf = LGBMClassifier(class_weight=\"balanced\")\n",
    "xgb_clf = XGBClassifier(scale_pos_weight=99)\n",
    "cat_clf = CatBoostClassifier(auto_class_weights='Balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy        : 0.6183649086874893\n",
      "Precision       : 0.09267335368512865\n",
      "Recall          : 0.5774456521739131\n",
      "F1              : 0.15971439308530627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.62      0.75     10982\n",
      "           1       0.09      0.58      0.16       736\n",
      "\n",
      "    accuracy                           0.62     11718\n",
      "   macro avg       0.52      0.60      0.46     11718\n",
      "weighted avg       0.90      0.62      0.72     11718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgb_clf.fit(train_X, train_y)\n",
    "pred_y = lgb_clf.predict(test_X)\n",
    "evaluate(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy        : 0.3872674517835808\n",
      "Precision       : 0.07549407114624505\n",
      "Recall          : 0.7785326086956522\n",
      "F1              : 0.13764112418928656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.36      0.52     10982\n",
      "           1       0.08      0.78      0.14       736\n",
      "\n",
      "    accuracy                           0.39     11718\n",
      "   macro avg       0.52      0.57      0.33     11718\n",
      "weighted avg       0.90      0.39      0.50     11718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf.fit(train_X, train_y)\n",
    "pred_y = xgb_clf.predict(test_X[train_X.columns])\n",
    "evaluate(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy        : 0.6804062126642771\n",
      "Precision       : 0.09480204686237544\n",
      "Recall          : 0.4782608695652174\n",
      "F1              : 0.15823780624859518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.69      0.80     10982\n",
      "           1       0.09      0.48      0.16       736\n",
      "\n",
      "    accuracy                           0.68     11718\n",
      "   macro avg       0.52      0.59      0.48     11718\n",
      "weighted avg       0.90      0.68      0.76     11718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat_clf.fit(train_X, train_y, verbose=0)\n",
    "pred_y = cat_clf.predict(test_X)\n",
    "evaluate(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation\n",
    "<pre>\n",
    "k = 3, 5, 10\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_validation(train_X.to_numpy(), train_y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(30000, 55) (7499, 55)\n",
      "(30000,) (7499,)\n",
      "1\n",
      "(30000, 55) (7499, 55)\n",
      "(30000,) (7499,)\n",
      "2\n",
      "(30000, 55) (7499, 55)\n",
      "(30000,) (7499,)\n",
      "3\n",
      "(30000, 55) (7499, 55)\n",
      "(30000,) (7499,)\n",
      "4\n",
      "(30000, 55) (7499, 55)\n",
      "(30000,) (7499,)\n"
     ]
    }
   ],
   "source": [
    "for train_X, val_X, train_y, val_y, i in cv:\n",
    "    print(i)\n",
    "    print(train_X.shape, val_X.shape)\n",
    "    print(train_y.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d43e22b5d3a7a0bd2e205ac27062b2ba3e10bf7033fb4f991038673b60a6900c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
